The project  uses the Workload Generation (Exp. Dist.) to generate synthetic times that depict the hour that a server has failed.
To simulate two servers in operation , we will use two separate workload generation formulas and assign a variable( x1 and x2 )to hold the values generated by the formulas. 
The values that are in  the server variables will be incremented by 10 and then added to two separate counters (server1TimeCounter and server2TimeCounter) that will be used in a while loop. The while loop will run as long as  the server time counters do not exceed 20 years.  

All times that are generated by servers 1 and 2 will be placed in two arrays and will be compared with each other.
If we find two values that are less than 10 hours from each other , then we will find the time when there was a total server shutdown. 

We will also run  all the information stated above in a for loop that will iterate 1000 times to get a total shutdown average. 
The program will output times when the server failed and when they were restored , the total amount of failures , the MTBF of server 1 and 2 and the time when both servers failed. 
The program will repeat the output 1000 times ( for each simulation)and at the end of the loop , output the actual total shutdown average.  


Below are iamges of the results 


Image of server # 1  failing and starting back up .

![image](https://user-images.githubusercontent.com/70728294/225662744-699c7914-e121-4427-98b9-b42404cd733d.png)


Image of server # 2 failing and starting back up . 

![image](https://user-images.githubusercontent.com/70728294/225662873-1c5dc7ec-e6df-471a-bb72-adb02e9c494e.png)


Results of simulator 

![image](https://user-images.githubusercontent.com/70728294/225663032-f412a8d5-ee5c-412e-8570-a82137c55b11.png)


